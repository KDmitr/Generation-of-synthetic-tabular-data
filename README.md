# Generation-of-synthetic-tabular-data

### **Валидация структурированного вывода LLM**
Эксперименты проводились на двух датасетах: Beijing (10 признаков), Forest (55 признаков); использовались LLM: LLAMA-3.3-70B-instruct, LLAMA-3.1-70B-instruct, LLAMA-3.1-8B-instruct и Deepseek-r1-8b; разный размер батча: 5,10 и 2 (для deepseek на forest, т.к. с большим размером батча модель не может работать).\
Выводы:
* Данные генерируется нужного формата: список JSON
* Метрики все считаются (за исключением некоторых эксперементов с Deepseek-r1-8b)
* Deepseek выдаёт относительно неплохие результаты относительно других моделей на небольшом датасете (10 признаков), но на большом датасете (55 признаков) качество у deepseek резко падает
* Модели LLAMA более устойчивы к размеру датасета, т.е. показывают высокие показатели качества как на маленьких, так и на больших датасетах
* Лучшая из используемых LLM - LLAMA-3.1-70B-instruct
* Изменение размера батча (количество строк) не влияет на качество
* у Deepseek были галлюцинации: 
    * на датасете Beijing модель придумала новые столбцы "Day" и "Hour" и заполнила все значения в этих столбцах NaN. Когда проделал ещё раз этот же эксперимент, этого уже не было.
     * на датасете Forest: есть строки, состоящие только из Nan, появились неведомые столбцы "id" и "data",  и в "data" есть странные не имеющие смысла значения в виде словарей
